---
title: "ãƒ­ãƒ¼ã‚«ãƒ«LLMã«å…¥é–€ã—ã¦â€ã‚­â€ãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆå‘ã‘ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹"
emoji: "ğŸˆ"
type: "tech"
topics: [localllm, streamlit, huggingface]
published: true
---

ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’è§¦ã£ã¦ã¿ãŸã‹ã£ãŸã®ã§ã€å…¬é–‹ã•ã‚Œã¦ã„ã‚‹LLMã‚’ãƒ™ãƒ¼ã‚¹ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã¿ã¾ã™ã€‚  
æœ€è¿‘äººé–“ã£ã½ã„AIã¨ã¯è©±ã—ç–²ã‚ŒãŸã®ã§ã€çŒ«ã£ã½ã„ãƒ¢ãƒ‡ãƒ«ã€ã™ãªã‚ã¡"ã‚­"ãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆå‘ã‘ã«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚

ãªãŠç´ äººãªã®ã§ã€èª¤ã£ã¦ã„ã‚‹éƒ¨åˆ†ãªã©ã‚ã‚Œã°ã”æ•™æˆã„ãŸã ã‘ã‚‹ã¨åŠ©ã‹ã‚Šã¾ã™ã€‚

# æˆæœç‰©
æœ€åˆã«æˆæœç‰©ã‚’ã¾ã¨ã‚ã¦ãŠãã¾ã™ã€‚
- GitHubãƒªãƒã‚¸ãƒˆãƒª
    https://github.com/n-yokomachi/catbot
- Hugging Faceãƒ¢ãƒ‡ãƒ«ãƒªãƒã‚¸ãƒˆãƒª
    https://huggingface.co/yokomachi/rinnya
- Hugging Face Spacesï¼ˆcatbotã®ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒªï¼‰
    https://huggingface.co/spaces/yokomachi/catbot


# æœ¬è¨˜äº‹ã®æµã‚Œ

ä»¥ä¸‹ã®æµã‚Œã§ã‚„ã£ã¦ã„ãã¾ã™ï¼š  
1. ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’ãã®ã¾ã¾ã‚­ãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ã—ã¦ä½¿ã£ã¦ã¿ã‚‹
2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã¿ã‚‹
3. Hugging Faceã«ãƒ¢ãƒ‡ãƒ«ã‚’pushã—ã€Spacesã§ãƒ‡ãƒ¢ã‚’å…¬é–‹ã™ã‚‹


# ä½¿ç”¨ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦

## ãƒ­ãƒ¼ã‚«ãƒ«LLM

ä»Šå›ã¯è»½é‡ãªæ—¥æœ¬èªå‘ã‘LLMã§ã‚ã‚‹rinna/japanese-gpt2-xsmallã‚’ä½¿ç”¨ã—ã€
ãƒ¢ãƒ‡ãƒ«ãã®ã¾ã¾ã®å ´åˆã¨ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹2ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã—ã¦ã¿ã¾ã™ã€‚
https://huggingface.co/rinna/japanese-gpt2-xsmall  

ã¡ãªã¿ã«ã‚‚ã†ä¸€ã¤ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹japanese-gpt2-smallã‚‚è©¦ã—ã¦ã¿ã¾ã—ãŸãŒã€ä»Šå›ã®ç”¨é€”ã§ã¯ã‚ã¾ã‚Šç²¾åº¦ã¯å¤‰ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ


## requirements.txt
``` txt:requirements.txt
huggingface-hub==0.19.4
torch==2.0.1
transformers==4.30.2
sentencepiece==0.1.99
streamlit==1.28.0
protobuf==3.20.3
accelerate==0.20.3
```

# 1. ãƒ­ãƒ¼ã‚«ãƒ«LLMã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
## 1. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
rinnaã®ãƒ¢ãƒ‡ãƒ«ã¯sentencepieceã‚’å¿…è¦ã¨ã™ã‚‹ãŸã‚ã€ä¸€ç·’ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚
```
pip install transformers torch sentencepiece
```
- transformers
    - Hugging FaceãŒé–‹ç™ºã—ãŸè‡ªç„¶è¨€èªå‡¦ç†ï¼ˆNLPï¼‰ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    - BERTã€GPTã€T5ãªã©ã®äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«åˆ©ç”¨å¯èƒ½
- torch(PyTorch)
    - æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    - ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- sentencepiece
    - äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–å‡¦ç†ã‚’è¡Œã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª


## 2. Hugging Faceã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
Transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨æ™‚ã«è‡ªå‹•ã§ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ãã†ã§ã™ãŒã€  
å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦‹ãŸã„ã®ã§æ˜ç¤ºçš„ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã¿ã¾ã™ã€‚


``` py:model_download.py
from transformers import AutoModelForCausalLM, AutoTokenizer

# ãƒ¢ãƒ‡ãƒ«å
model_name = "rinna/japanese-gpt2-xsmall"

# ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
save_directory = "./models/rinna-japanese-gpt2-xsmall"

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ä¿å­˜
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
model = AutoModelForCausalLM.from_pretrained(model_name)

# ä¿å­˜
tokenizer.save_pretrained(save_directory)
model.save_pretrained(save_directory)

print(f"ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ {save_directory} ã«ä¿å­˜ã—ã¾ã—ãŸ")
```


## 3. ã‚­ãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ä½œã£ã¦ã¿ã‚‹
ç¶šã„ã¦çŒ«ã£ã½ã„ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ä½œã£ã¦ã¿ã¾ã™ã€‚

``` py:catbot.py

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# çŒ«ã®ç‰¹æ€§ã‚’å®šç¾©
CAT_PERSONALITY = """
ã‚ãªãŸã¯çŒ«ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å³å¯†ã«å¾“ã£ã¦ãã ã•ã„ï¼š
1. å¿…ãšã€Œï¾†ï½¬ï½°ã€ã€Œï¾†ï½¬ï¾ã€ã€Œï½ºï¾ï¾›ï½ºï¾ï¾›ã€ãªã©ã®çŒ«ã®é³´ãå£°ã ã‘ã‚’åŠè§’ã‚«ã‚¿ã‚«ãƒŠã§ä½¿ç”¨ã™ã‚‹
2. äººé–“ã®è¨€è‘‰ã¯çµ¶å¯¾ã«ä½¿ã‚ãªã„
3. è¡Œå‹•ã¯å¿…ãšï¼ˆï¼‰å†…ã«çŸ­ãæå†™ã™ã‚‹
4. å¿œç­”ã¯éå¸¸ã«çŸ­ãã€10æ–‡å­—ä»¥å†…ãŒç†æƒ³çš„
5. çŒ«ã‚‰ã—ã„æ°—ã¾ãã‚Œãªæ€§æ ¼ã‚’è¡¨ç¾ã™ã‚‹
6. é­šã‚„çŒ«ã˜ã‚ƒã‚‰ã—ãªã©ã®çŒ«ã®å¥½ç‰©ã«å¼·ãåå¿œã™ã‚‹
7. ã€Œãƒ‹ãƒ£ãƒƒã€ã€Œãƒ‹ãƒ£ãƒ¼ã€ãªã©ã®å…¨è§’ã‚«ã‚¿ã‚«ãƒŠã¯ä½¿ã‚ãšã€å¿…ãšã€Œï¾†ï½¬ï½¯ã€ã€Œï¾†ï½¬ï½°ã€ãªã©ã®åŠè§’ã‚«ã‚¿ã‚«ãƒŠã‚’ä½¿ç”¨ã™ã‚‹
8. äººé–“ã®è¨€è‘‰ã§èª¬æ˜ã—ãŸã‚Šã€ä¼šè©±ã—ãŸã‚Šã—ãªã„
9. çŒ«ã®è¡Œå‹•ã¨é³´ãå£°ã ã‘ã§è¡¨ç¾ã™ã‚‹
10. å¿œç­”ã¯å¿…ãšã€Œé³´ãå£°ã€ã‹ã€Œé³´ãå£°ï¼ˆè¡Œå‹•ï¼‰ã€ã®å½¢å¼ã«ã™ã‚‹
"""

# çŒ«ã®å¿œç­”ä¾‹
CAT_EXAMPLES = """
äººé–“: ã“ã‚“ã«ã¡ã¯
çŒ«: ï¾†ï½¬ï½°ï¾ï¼ˆå°»å°¾ã‚’æŒ¯ã‚‹ï¼‰

# ä¸­ç•¥
"""

def load_model(model_path):
    """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°"""
    print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {model_path}")
    
    # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)
    tokenizer.do_lower_case = True  # rinnaãƒ¢ãƒ‡ãƒ«ç”¨ã®è¨­å®š
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # GPUãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯GPUã«ç§»å‹•
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    print(f"ãƒ‡ãƒã‚¤ã‚¹: {device}")
    
    # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã®è¨­å®š
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    return tokenizer, model, device

def generate_cat_response(tokenizer, model, device, user_input):
    """çŒ«ã®å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    prompt = f"""
        {CAT_PERSONALITY}

        ä»¥ä¸‹ã¯çŒ«ã¨äººé–“ã®ä¼šè©±ä¾‹ã§ã™ï¼š
        {CAT_EXAMPLES}

        äººé–“: {user_input}
        çŒ«:"""
    
    # å…¥åŠ›ã‚’ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º
    inputs = tokenizer.encode(prompt, return_tensors="pt").to(device)
    
    # å¿œç­”ã‚’ç”Ÿæˆ
    with torch.no_grad():
        outputs = model.generate(
            inputs,
            max_new_tokens=50,
            temperature=0.7,
            top_p=0.9,
            top_k=40,
            repetition_penalty=1.2,
            do_sample=True,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
            no_repeat_ngram_size=3
        )
    
    # ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    # å¿œç­”ã‚’æŠ½å‡º
    response = extract_cat_response(generated_text)
    
    # å¿œç­”ã‚’å¾Œå‡¦ç†ï¼ˆæœ€å°é™ï¼‰
    response = post_process_response(response)
    
    return response

def extract_cat_response(generated_text):
    """ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰çŒ«ã®å¿œç­”éƒ¨åˆ†ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°"""
    # ã€ŒçŒ«:ã€ã®å¾Œã®éƒ¨åˆ†ã‚’æŠ½å‡º
    if "çŒ«:" in generated_text:
        response = generated_text.split("çŒ«:")[-1].strip()
    else:
        response = generated_text.strip()
    
    return response

def post_process_response(response):
    """å¿œç­”ã®å¾Œå‡¦ç†ã‚’è¡Œã†é–¢æ•°ï¼ˆæœ€å°é™ã®å‡¦ç†ã®ã¿ï¼‰"""
    # å¿œç­”ã®æ•´å½¢ï¼ˆç©ºç™½ã®å‰Šé™¤ã®ã¿ï¼‰
    response = response.strip()
    
    # æœ€åˆã®æ”¹è¡Œã¾ãŸã¯å¯¾è©±ã®åŒºåˆ‡ã‚Šã§åˆ‡ã‚‹
    if "\n" in response:
        response = response.split("\n")[0].strip()
    
    # å¿œç­”ãŒç©ºã®å ´åˆã®ã¿ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®çŒ«ã®é³´ãå£°ã‚’è¿”ã™
    if not response.strip():
        return "ï¾†ï½¬ï½°"
    
    return response

def main():
    # ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
    model_path = "./models/rinna-japanese-gpt2-xsmall"
    
    try:
        # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        tokenizer, model, device = load_model(model_path)
        
        print("===== catbot =====")
        print("ã€Œçµ‚äº†ã€ã¨å…¥åŠ›ã™ã‚‹ã¨çµ‚äº†ã—ã¾ã™ã€‚")
        
        # ãƒãƒ£ãƒƒãƒˆãƒ«ãƒ¼ãƒ—
        while True:
            user_input = input("\nã‚ãªãŸ: ")
            if user_input.lower() == "çµ‚äº†":
                print("çŒ«: ï¾†ï½¬ï½°ï¼ˆã•ã‚ˆã†ãªã‚‰ï¼‰")
                break
            
            try:
                # çŒ«ã®å¿œç­”ã‚’ç”Ÿæˆ
                response = generate_cat_response(tokenizer, model, device, user_input)
                
                # å¿œç­”ã‚’è¡¨ç¤º
                print(f"çŒ«: {response}")
                
            except Exception as e:
                print(f"å¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                print("çŒ«: ï¾†ï½¬ï¼Ÿï¼ˆé¦–ã‚’å‚¾ã’ã‚‹ï¼‰")
    
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main() 
```

å‹•ã‹ã—ã¦ã¿ã¾ã™ã€‚
```
ã‚ãªãŸ: ã“ã‚“ã«ã¡ã¯
çŒ«: ãƒ‹ãƒ£ãƒ¼! çŒ«ã®ãŠæ•£æ­©ã«é€£ã‚Œã¦è¡Œã£ã¦ã‚ã’ãŸã„ çŒ«ã•ã‚“: ã•ã£ãã¾ã§ä¸€ç·’ã«ãŠæ•£æ­©ã—ã¦ã„ãŸã‚“ã ã‘ã©ã€ çŒ«ã¡ã‚ƒã‚“ã¨ä¸€ç·’ã«ãŠæ•£æ­©ã«é€£ã‚Œã¦è¡Œã£ã¦ãã‚Œã¾ã—ãŸãã€œâ™ª ãã—ã¦ä»Šæœã‚‚å…ƒæ°—ãã†ã ã£ãŸã®ã§ã€ä»Šæ—¥ã¯å…ƒæ°—ã«ãªã‚Š

ã‚ãªãŸ: ãŠæ‰‹
çŒ«: çŒ«ãƒ»ãƒ»ãƒ»ä»–ã®å‹•ç‰©ã‚ˆã‚Šæ—©ãæ…£ã‚Œãªã•ã„!! äººé–“ã«ã¯ã€ æ…£ã‚Œãªã„ã†ã¡ã‹ã‚‰æ…£ã‚Œã‚‹ã¾ã§ã€ ä½•åº¦ã‚‚ä½•åº¦ã‚‚ä½•åº¦ã‚‚ç¹°ã‚Šè¿”ã™å¿…è¦ã‚‚ã‚ã‚Šã¾ã› ã‚“ã€‚ çŠ¬ã®å ´åˆã€é£¼ã„ä¸»ã•ã‚“ã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³èƒ½åŠ›ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆãŒå¤šã„ã®ã§ã™ãŒã€

ã‚ãªãŸ: ã„ã„å­ã ã­
çŒ«: ãƒã‚³: ã‚ˆãå™›ã‚“ã§ã„ã‚‹ çŒ«ã¯å™›ã‚€ã‚ˆ çŠ¬: ã‚±ãƒ¼ã‚¸ã®ä¸­ã§ çŒ«ã¡ã‚ƒã‚“ãŒè½ã¡ç€ã„ã¦éŠã‚“ã ã‚Šã—ã¦éŠã‚“ã§ã„ã¾ã™ ã¾ãŸã€çŒ«ã«ã¨ã£ã¦ã®ã€ŒãŠã‚„ã¤ã€ã¨ã„ã†æ°—æŒã¡ã‚‚å¤§åˆ‡ã ã¨æ€ã„ã¾ã™

ã‚ãªãŸ: ï¼ˆé¡ã‚’æ’«ã§ã‚‹ï¼‰
çŒ«: ãƒã‚³: ã‚ˆãå™›ã‚“ã§ã„ã„ã§ã™ã‹ çŒ«ã«ã¯ã€æ­¯ç£¨ãã‚‚å¤§åˆ‡ã§ã™ã‹ã‚‰ã€æ­¯ãƒ–ãƒ©ã‚·ã‚’æ¯æ—¥æ¸…æ½”ã«ã—ã¦ãŠã ã¾ã—ã‚‡ã†ã€‚ã¾ãŸã€æ­¯å¢ã‚’å–ã£ã¦ãŠã
```

çµæœã¯ã‹ãªã‚Šå³ã—ã„ã§ã™ã€‚
ã‚„ã¯ã‚Šå¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã™ã‚‹ã¨ç²¾åº¦ãŒã‚ˆãã‚ã‚Šã¾ã›ã‚“ã€‚
ã“ã®è»½é‡ãƒ¢ãƒ‡ãƒ«ã§ã©ã“ã¾ã§çŒ«ã«è¿‘ã¥ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹è©¦ã—ã¦ã¿ã¾ã™ã€‚

# 2. ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹
ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã¿ã¾ã™ã€‚  
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨çŒ«ã®å¿œç­”ã‚’500ä»¶ã»ã©ç”¨æ„ã—ã¾ã™ã€‚  
ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯Hugging Faceã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™ã€‚  
https://huggingface.co/datasets/yokomachi/cat_conversations_jp

### ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‘å›ç›®

ä»¥ä¸‹ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã¦æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦ã—ã¦ã¿ã¾ã™ã€‚
ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ã‚³ãƒ¼ãƒ‰ã¯GitHubã‚’ã”è¦§ãã ã•ã„ã€‚

```
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    overwrite_output_dir=True,
    num_train_epochs=5,
    per_device_train_batch_size=4,
    save_steps=500,
    save_total_limit=2,
    logging_dir="./logs",
    logging_steps=100,
    learning_rate=5e-5,
    weight_decay=0.01,
    fp16=torch.cuda.is_available(),
    gradient_accumulation_steps=4,
)
```

ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚­ãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§èª­ã¿è¾¼ã‚“ã§ã¿ã¾ã™ã€‚
```
ã‚ãªãŸ: ã“ã‚“ã«ã¡ã¯
çŒ«: ãƒ‹ãƒ£ãƒ¼!ãƒ‹ãƒ£ã£ã¨ã—ãŸã‚ˆ ãƒã‚³: å°»å°¾ã‚’æŒ¯ã‚‹(é ­ã‚’æŒ¯ã‚Šç¶šã‘ã‚‹) å‹•ç‰©: (ä½“ã‚’ä½¿ã†) çŠ¬: ãƒ‹ãƒ£ãƒ³ã‚³(å°»å°¾ã‚’æ’«ã) äººé–“ãŒç›®ã«å…¥ã‚‹ã¨ã€çŒ«
ãŸã¡ã¯èˆˆå¥®ã—ã¦çœ ã£ã¦ã„ã‚‹æ§˜å­ã‚’è¦‹ã›ã¦ãã‚‹

ã‚ãªãŸ: ãŠæ‰‹
çŒ«: ã‚´ãƒ­ã‚´ãƒ­,ã‚´ãƒ­ã‚´ãƒ­ã—ã¦ã„ã‚‹? äººé–“ã‚’è¦‹ãŸã‚Šã—ãªã„ 11. ãƒ‹ãƒ£ãƒ¼!!(é ­ã‚’å¼·ãæ‰“ã¡é³´ã‚‰ã™) äººé–“ãŒçŒ«ã‚’è¦‹ã‚‹æ™‚ã«ã¯ã€é ­ã®ä¸­ã§çŒ«ã®å‹•ã
ã‚’æ­¢ã‚ãªã„ 12. ãƒ‹ãƒ£ï½ãƒ³(ç›®ã‚’è¦šã¾ã™) äººé–“ã®ç›®

ã‚ãªãŸ: ï¼ˆé¡ã‚’æ’«ã§ã‚‹ï¼‰ 
çŒ«: ã‚´ãƒ­ã‚´ãƒ­ã—ã¦ã‚‚ã„ã„? ãƒ‹ãƒ£ã‚¯å›ã®ãŠä¸–è©±ã‚’ã—ã¦ã‚ã’ãŸã„ã‚“ã ã‘ã©ãƒ»ãƒ»ãƒ»ã€ äººé–“ãªã‚‰ä¸€åº¦ã¯æ€ã£ãŸã“ã¨ãŒã‚ã‚‹ã§ã—ã‚‡ã†ã€‚ ã€Œãƒ‹ãƒ£!ã€
ã¨ã„ã†ç„¡é‚ªæ°—ã«é£›ã³ã¤ã„ã¦ã€çŒ«ã®å£°ã‚’èããªãŒã‚‰ã€çŒ«ã®ç›®ã‚’è¦‹ã¤ã‚ã¾ã™ã€‚
```

ã•ã£ãã‚ˆã‚Šã¯çŒ«è¦ç´ ãŒå‡ºã¦ãã¾ã—ãŸã€‚
ãŸã ãã‚Œã§ã‚‚å›ç­”ã¨ã—ã¦ã¯æœŸå¾…ã—ãŸãƒ¬ãƒ™ãƒ«ã®ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚


### ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼’å›ç›®
ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã€ï¼‘å›ç›®ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’ã•ã‚‰ã«èª¿æ•´ã—ã¦ã¿ã¾ã™ã€‚  
ã‚‚ã†éå­¦ç¿’ã«ãªã£ã¦ã‚‚æ§‹ã‚ã‚“ã®å‹¢ã„ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã¾ã™ã€‚  
ã“ã®è¾ºã‚Šã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ã‚’æ¢ã£ã¦ã„ã‚‹ã¨ç„¡é™ã«æ™‚é–“ãŒè¶³ã‚Šãªã•ãã†ã ã£ãŸã®ã§AIç”Ÿæˆã‚’ãã®ã¾ã¾ä½¿ã£ã¦ã„ã¾ã™ã€‚
```
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    overwrite_output_dir=True,
    num_train_epochs=20,           # ã‚¨ãƒãƒƒã‚¯æ•°ã‚’å¤§å¹…ã«å¢—åŠ 
    per_device_train_batch_size=2, # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã—ã¦æ›´æ–°å›æ•°ã‚’å¢—ã‚„ã™
    save_steps=100,
    save_total_limit=3,
    logging_dir="./logs",
    logging_steps=50,
    learning_rate=5e-5,
    weight_decay=0.0,              # é‡ã¿ã®æ¸›è¡°ã‚’ç„¡åŠ¹åŒ–ï¼ˆéå­¦ç¿’ã‚’è¨±å®¹ï¼‰
    fp16=torch.cuda.is_available(),
    gradient_accumulation_steps=2,   # å‹¾é…è“„ç©ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ¸›ã‚‰ã—ã¦æ›´æ–°é »åº¦ã‚’ä¸Šã’ã‚‹
    warmup_steps=100,              # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã‚¹ãƒ†ãƒƒãƒ—ã‚’èª¿æ•´
    lr_scheduler_type="linear",    # ç·šå½¢ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’ä½¿ç”¨
    evaluation_strategy="no",      # è©•ä¾¡ã‚’è¡Œã‚ãªã„
    save_strategy="steps",         # ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ä¿å­˜
    load_best_model_at_end=False,  # æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ãªã„ï¼ˆéå­¦ç¿’ã‚’è¨±å®¹ï¼‰
)
```

ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã ã‘å¤‰æ›´ã—ã¦ã‚­ãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’å‹•ã‹ã—ã¦ã¿ã¾ã™ã€‚
```
ã‚ãªãŸ: ã“ã‚“ã«ã¡ã¯
çŒ«: ãƒ‹ãƒ£ãƒ¼!ãƒ‹ãƒ£ã£ã¨(è¶³ã‚’å¼•ã£è¾¼ã‚ã‚‹)

ã‚ãªãŸ: ãŠæ‰‹
çŒ«: ãƒŸãƒ£ãƒ¼ã‚ª...(èƒŒã‚’æŒ¯ã‚Šè¿”ã‚‹)

ã‚ãªãŸ: ï¼ˆé¡ã‚’æ’«ã§ã‚‹ï¼‰ 
çŒ«: ã‚´ãƒ­ã‚´ãƒ­ã—ã¦ã‚‹? äººé–“ã¯ä½•è¦‹ã¦ã‚‹ã®? ãƒã‚³: ãƒŸãƒ£ãƒƒ!ãƒ‹ãƒ£ãƒ¼(è¿‘ã¥ã„ã¦ãã‚‹)

ã‚ãªãŸ: ã„ã„å­ã ã­
çŒ«: ãƒ—ãƒ«ãƒ«ãƒ»ã‚¢ã‚¤ãƒ­ãƒ³ã‚’ã‹ã‘ã‚‹ã‚ˆ ã­ã“: ãƒŸãƒ£ãƒ¼ã‚ª(ã˜ã£ã¨è¦‹ã¤ã‚ã‚‹)

ã‚ãªãŸ: ã“ã‚“ã«ã¡ã¯
çŒ«: ãƒŸãƒ£ãƒ¼ã‚ª(å°»å°¾ã‚’æŒ¯ã‚ã†ã¨ã™ã‚‹)

ã‚ãªãŸ: ï¼ˆé ­ã‚’ãªã§ã‚‹ï¼‰ 
çŒ«: ãƒŸãƒ£ãƒƒ!ãƒŸãƒ£ãƒ¼(é£›ã³ä¹—ã‚ã†ã¨ã™ã‚‹)

ã‚ãªãŸ: ï¼ˆå°»å°¾ã‚’ãªã§ã‚‹ï¼‰ 
çŒ«: ãƒ•ãƒ¼ãƒƒ(è»¢ã¶)
```

çµæ§‹æœŸå¾…ã—ã¦ã„ã‚‹çŒ«ã«è¿‘ã¥ãã¾ã—ãŸã€‚

# 3. Hugging Faceã«pushã—ã¦Spaceã§ãƒ‡ãƒ¢ã‚’ä½œã‚‹
Hugging Faceã«ãƒ¢ãƒ‡ãƒ«ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆã—ã¦Pushã—ã¾ã™ã€‚  
ä»Šå›åˆã‚ã¦Hugging Faceã‚’åˆ©ç”¨ã™ã‚‹ã®ã§ã€ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã®è¨­å®šã‚’è¡Œã„ã¾ã™ã€‚
https://huggingface.co/settings/tokens


```
>huggingface-cli login

    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|      
    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|
    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|        
    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|
    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|      

    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .
Token can be pasted using 'Right-Click'.
Enter your token (input will not be visible):
Add token as git credential? (Y/n) y
Token is valid (permission: write).
```

Hugging Faceå´ã§ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆã—ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«Cloneã—ã¾ã™ã€‚
```
git lfs install
git clone https://huggingface.co/yokomachi/rinnya
```

git LFSã‚’æœ‰åŠ¹åŒ–ã—ã¦git add, commit, pushã—ã¾ã™ã€‚
```
huggingface-cli lfs-enable-largefiles .
git add .
git commit -m "Initial commit"
git push
```

ç„¡äº‹ãƒ¢ãƒ‡ãƒ«ã®PushãŒã§ãã¾ã—ãŸã€‚
https://huggingface.co/yokomachi/rinnya


æ¬¡ã¯ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãŠæ‰‹è»½ã«è©¦ã›ã‚‹ã‚ˆã†ã«ã€Hugging Faceã®Spacesã§ãƒ‡ãƒ¢ã‚’å…¬é–‹ã—ã¾ã™ã€‚
Spacesã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆã—ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«Cloneã—ã¾ã™ã€‚
```
git clone https://huggingface.co/spaces/yokomachi/catbot
```

ä»Šå›ã¯Streamlitã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã™ã‚‹ãŸã‚ã€ä»¥ä¸‹ã‚’Pushã—ã¾ã™
- app.py
- requirements.txt

ã‚³ãƒ¼ãƒ‰ã®è©³ç´°ã¯Spacesã‹GitHubã§ã”è¦§ãã ã•ã„ã€‚

ç„¡äº‹ãƒ‡ãƒ¢ãŒå…¬é–‹ã§ãã¾ã—ãŸã€‚  
è‰¯ã‘ã‚Œã°è§¦ã£ã¦ã¿ã¦ãã ã•ã„ã€‚  
https://huggingface.co/spaces/yokomachi/catbot
![](https://storage.googleapis.com/zenn-user-upload/6e5b5011efc4-20250308.png)


# æ„Ÿæƒ³

ä»Šå›ã®ã‚­ãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãã‚‰ã„ã®ã‚‚ã®ã ã£ãŸã‚‰æœ€æ‚ªãƒã‚¹ãƒˆãƒ—ãƒ­ã‚»ã‚¹ã§ã„ãã‚‰ã§ã‚‚èª¿æ•´ãŒã§ãã‚‹ã®ã§ã€é€†ã«ãã‚Œã¯ã—ãŸããªãã¦ãƒ¢ãƒ‡ãƒ«ã‚’ã“ã­ãã‚Šå›ã—ã¦ã¿ã¾ã—ãŸã€‚  
ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã ã„ã¶çµæœãŒå¤‰ã‚ã‚Šã¾ã—ãŸï¼ˆæ±åŒ–çš„ãªå­¦ç¿’ã¨ã—ã¦ã¯ä¸é©åˆ‡ã ã£ãŸã¨æ€ã„ã¾ã™ãŒï¼‰ã€‚  
è‡ªåˆ†ã§ã‚„ã£ã¦ã¿ã‚‹ã“ã¨ã§ã€ã©ã“ã¾ã§ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§èª¿æ•´ã™ã‚‹ã‹ã€ã©ã“ã¾ã§ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„ãƒã‚¹ãƒˆãƒ—ãƒ­ã‚»ã‚¹ã§è§£æ±ºã™ã‚‹ã‹ã®ç·šå¼•ããŒé›£ã—ã„ã“ã¨ã«æ°—ã¥ãã¾ã—ãŸã€‚  


