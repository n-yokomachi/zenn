---
title: "生成AIを使って正しかろう内容をただ出力させただけの技術記事は存在する意味がない"
emoji: "🫧"
type: "idea"
topics: [llm, アウトプット, 生成AI, 技術記事]
published: true
---

:::message
この記事は人間が書き、校正にのみ生成AIを使用しています。
:::

# はじめに
この記事は個人の意見の表明であり、所属する組織と関係するものではない。
と予防線を張ったところで…

さて、私は日常的に生成AIを使用している。
仕事とプライベートの両方でコーディングや画像・動画の生成、上の注釈の通りこうした記事の校正など、様々な場面で生成AIを活用している。
生成AIさまさま。
もうこれがないとコードが書けない。
生成AIマジ感謝。
一方で私は、生成AIに出力させた技術記事に対してはまだ否定的な立場だ。
もっと正確な言い方をすると、「生成AIを使って正しかろう内容をただ出力させただけの技術記事は存在する意味がない」と思っている。
また、「生成AIの使用箇所が明記されていないが、生成AIの匂いがする技術記事」も自分にとっては意味がない。
逆説的に、記事の校正やスクラップの整理記事の作成、生成したコードや構成図などをレビューしたうえで公開することには肯定的である。
同じく、記事を書く上での情報収集やアイデア出しも、それがちゃんと筆者による事実確認やレビュー、検証を経ているのなら何も言うことはない。


# 正しさの保証がない
なんか妙に長ったらしく、時折\**太字\**や\*イタリック\*のマークダウン記号がそのまま出力されている記事。
「まさにその通りで」「✨ ○○の劇的向上　🚀 ○○の自動化」みたいなよく見る語彙に溢れた記事。
最近はもう生成AIの匂いがする技術記事は読み飛ばしている。

まず、生成AIの匂いのする記事には読者にとって正しさの保証がない。
読者にはその記事を書くために使用した生成AIのモデルやプロンプト、コンテキスト、AIアプリケーション、検索ツール、MCPツール、コーディングツール等々が分からない。
そのモデルのカットオフがいつなのかも分からないし、Web検索しているのかも分からない。していたとして最新の情報が拾えているかも分からない。
またそれらがたとえ明らかにされていたとして、ハルシネーションを起こしている可能性も十分ある。
ので、生成AIに出力させた技術記事は公開前にその内容の正確さを確認する必要があるのだが、それがされているかもやっぱり分からない。
というわけで読者はその記事の正確さを信頼できない。

正確さが担保されていない記事が並べ立てる事実らしきものには意味がない。
信頼できない語り手の書いた記事だ。
騙されたくない読者は地の文を全部疑わなきゃならない。


# そもそも正しさを求めていない
「いや待て、そもそも人間が書いたものだって同様に正確さは保証されていないじゃあないか」
その通りだ。
そもそも私は正確な情報を手に入れたいとき公式ドキュメントを読む。
つまるところ、そもそも私は技術記事に対してあまり正しさを求めていない。
もちろん正しいのに越したことはないが、自分の中では二の次だ。

ではどういうときに技術記事を読んでいるかというと大体以下のケース。
1. 公式ドキュメントに書いていないこと、公式通りにやってうまくいかないことを解決したいとき
2. やたらめったら詳しい人が技術要素の解説をしてくれるとき
3. 実装手法、設計パターン、組織論など、人により意見の分かれる議論が技術記事間やコメント欄でされているとき

> 2. やたらめったら詳しい人が技術要素の解説をしてくれるとき

このうち2についてはその内容の正確さが最も重要視される。
この点において、前述のとおり生成AIに出力させた記事の正確さは担保されていないので私は読まないし、一方、人間が書いているものに関してはその人の経験、知識、そしてそれらを共有しようという筆者の責任感と良心を信頼しているから読むことができる。
もちろん人が書いているからと言ってすべてを鵜吞みにするわけでもない。

> 3. 実装手法、設計パターン、組織論など、人により意見の分かれる議論が技術記事間やコメント欄でされているとき

また3に関して言えば、そもそも生成AIに記事を出力させてまで議論に参加している人を私はあまり観測していない。
いたとして、それこそそんなことをする意味が分からないので、この場であれこれ記事の意味について話す意味すらない。
ただこの点に関しては例外があって、例えば生成AIに出力させた技術記事に対して読者がコメント欄で議論しているとかあれば、面白がってそれを読むことがあるかもしれない。



# 検証を他人に委託する

> 1. 公式ドキュメントに書いていないこと、公式通りにやってうまくいかないことを解決したいとき

これはどちらかというと正しさが求められるときだが、それでもなお真に技術的な正確さは求めていない。
求めているのは、筆者が試したこと、その検証結果、手を動かして分かったこと、手を動かすときに間違えたこと、筆者の予想と事実のギャップ、実装にかかった時間、めんどくさい作業かどうか、実装後に計測した速度、コスト。
他にもあるかもしれないが、今思いつくのは主にこれら事実だ。検証結果だ。

検証、そう検証だ。
私は検証の手間を省きたいから技術記事を読んでいる。
実際に人間が試したトラブルシュートの方法をかき集めたり、新規に公開されたサービスを使ってみた感想を眺めたり、公式ドキュメントに載っていない実際に動く実装だったり。
人によって違う環境起因で発生するトラブルだったり、具体的な案件やシナリオで導入した技術要素の選定理由だったり。
AWSのインスタンスサイズごとのコストを実際に計測した比較だったり、LLMの評価を行った結果を見たり。

多くの人々が日々検証結果を技術記事として残していく。
私にはそれらと同じレベル・物量の検証をする時間もないし知識や技術もない。
なので私は技術記事を読む。
私は技術検証を他人に委託している。


もちろん検証の過程で生成AIを使用することには何も問題がない、どころかやるべきだ。
コーディングエージェントに検証用のコードを出力させてもいいし、検証作業に必要な手順をLLMアプリに聞いてもいい。
それは生成AIを正しく道具として用いて、人間が検証しているからだ。

またベースとなる検証が実際に行われており、その検証結果が記事に書かれているのなら、記事そのものを生成AIに出力させることにそこまで抵抗感もない。
だがレビューはちゃんとしてほしいし、その証拠として生成AIの匂いは消してほしい。
「レビューしました」「検証は自分でしました」って記事内に書いてほしい。

気づかれた方もいるかもしれないが、私は今意識して「生成AIに出力させた」という言い方をしている。
生成AIというペンを使って書いたものは、そのペンを握った筆者に責任を持ってほしい。
ハルシネーションが残された記事はつまり、筆者が誤った情報を公開していることに等しい。

また例えレビューを通していても、生成AIの残り香がしている記事は、筆者の技術や読者への向き合い方が疑われることにも繋がる。
生成AI臭い記事に時間を無駄にされた経験のある人は、自分が記事を書く側に回ったとき、あの鼻につく生成AIの匂いを残そうとはしないだろうから。

一方で人間が書いた記事、もしくは人間がレビューして消臭した記事においては、「やったからには記事にするか」あるいは「記事を書くからにはやっとくか」という筆者の良心に対して、私は一定の信頼を寄せることができる。


# 手を動かした人間の良心を信頼している

ここまでで「良心」という言葉が２回出てきた。
そう、私は筆者の人間的道徳的な良心を頼りにしている。

もちろん人間が書いたから全部信用しようというわけではない。
ただその記事における検証内容が、どうやら実際に手を動かしたものらしいぞ、という判断のために人間が書いているということ、ひいてはその良心をあてにしているに過ぎない。
だが技術検証記事において最も重要なのは、結局その良心が出力させた赤裸々な事実だと私は思っている。
その人間臭さをアピールするための手段として、人間が書くこと、またはレビューの証拠に生成AIの匂いを消臭しておくことは今後自衛にもなるだろう。


# おしまい
いや、最近某CSPのブログリレーで生成AI臭がすごい記事が出てて、それって組織そのものへの信頼を損なっているんじゃないかな、と思ったので書きました。

今の時点での私の感覚は書いた通りとなりますが、これも数か月後、数年後とかには状況が全く変わっているのかもしれません。
この記事では意識して"AIに出力させた"と書いてきましたが、いずれは"AIが書いた"と主語が変わるときも来るでしょう。
それまでの間、私は手で検証して手で技術記事を書きます。
