---
title: "\"人\"が頑張るAI駆動開発"
emoji: "🚙"
type: "idea"
topics: [sdd, ai駆動開発, aiエージェント, チーム開発]
published: true
---


:::message
この記事は人間が書き、記事の校正に生成AIを使用しています。
:::

この記事は2025/12/23に発表した以下のLT資料をもとに執筆しています。
@[speakerdeck](547c11826879450f841eff1cfee8ff18)


# はじめに
AI駆動開発も今や珍しくなくなりました。
Gartner社の調査によればAI駆動かどうかはともかく[コード生成における利用率が約49%という調査結果](https://it.impress.co.jp/articles/-/28487)もあります。


今回の記事では、実際にAI駆動開発やSDDをやってみたり、イベントなどで見聞きしたことから感じた課題を4つのセクションに分けて書きたいと思います。

# SDDではSpecが成果物を左右する

## SDDとは

まずSDD（Spec-Driven Development）について簡単に。

SDDはSpec-Driven Development（仕様駆動開発）の略で、Vibe Codingとは異なるアプローチです。最初に仕様（Specification）を詳細に定義・文書化し、AIがそれらを具体化するように実装する開発手法です。

個人的にはある意味でAI導入前の開発フローと大きく変わらないイメージを持っています。実際、SDDの名前がつく前から、設計とか技術スタックとかタスクとかをMarkdownに書いてからAIに実装させてたっていう方も、私を含めて多いのではと思います。

ちなみにSDDの名前が出始めたのは、（観測範囲では）AWSの[Kiro](https://kiro.dev/)がきっかけかと思います。Kiroのリリース後、GitHubの[Spec-kit](https://github.com/github/spec-kit)がリリースされて、広く周知されるようになった認識です。今ではOSSの[cc-sdd](https://github.com/gotalab/cc-sdd)なども出ていますね。


## Specが成果物を左右する

ちょっとした事例ですが、以前社内でAIハッカソンが開催されました。
「AI駆動開発であること or AIを組み込んでいること」というテーマです。
私は個人参加でSDDをやってみることにしました。
（ちなみにこの時はまだSpec-kitもcc-sddもリリース前なので、Claude Codeで自力SDDをやっています）

で作ったのは以前こちらの記事で書いたSNSアプリになります。
https://zenn.dev/yokomachi/articles/20250830_mastra_moderator_ai_agent

AI機能として「ユーザーの投稿にセンシティブな情報が含まれているとき、AIが判定して改善案を提案する」という機能を入れていました。
開発当時は他のチームと被らなさそうだしいい感じと思っていたのですが、実際のところ、このAI機能はほとんど使われている気配もないし、結果的にあんまりウケもしませんでした。

なぜならそう、そもそも「このアプリを使う大半の常識的なユーザーにはAIからの提案もされない」、つまり、「このアプリにAI機能が組み込まれていること自体がわからない」というAIハッカソンにおいては致命的なミスがあったからです。
最初のSpecの時点で成果物を想像したうえでのレビューが足りていなかったのが大きな敗因だったと思います。

## Specの修正は結構手間

そしてSpecはできるだけ最初に決め切りたいところです。

後から修正ももちろん可能ですが、
1. ドキュメントの修正
2. コンテキストに反映
3. コードに反映

という流れが必要で、過去のコンテキストが邪魔をしたり、チーム開発ならメンバー間で同期を取る必要があったりで結構手間がかかります。

というわけでこのセクションの結論としては、SDDにおいてはSpecの質が成果物を左右し、最初のSpecをいかに詰められるかがスピードを左右するというのが今思っていることになります。
チーム開発においてはDevはもちろん、ドキュメントを触るSMやPOも含めて、初期段階でのレビューを徹底してやる必要があると考えています。


# AIフレンドリーなコードを

## これまでのリーダブルコード、これからのリーダブルコード

これまでリーダブルコードを書くのは「人が読みやすいコードは人が直しやすい」からでした。
そしてこれからは「AIが読みやすいコードはAIが直しやすい」ことも意識する必要があります。

コーディングエージェントもベースはLLMです。自然言語や広く使われるプログラミング言語、広く使われている実装パターンなどから学習し、次のトークンを予測するのが基本的なプロセスです。
よって「人が読みやすいコードはAIも読みやすい」し、「AIが読みやすいコードはAIが直しやすい」はずです。AIが直しやすいということはコンテキストが抑えられるし、トークン消費を節約することにもつながります。


## 人が読みやすいコードはAIに直させやすい

そしてそもそも、人が読みやすいコードは人がAIに直させやすいということでもあります。
人が読みやすいコードはそれ自体が説明性を持っています。
コードが説明性を持っていれば、AIへ与える指示の中に説明を入れる必要性が低くなります。
説明を省けるということはAIへのプロンプトを考えるために人間がコードを読む時間を減らすことにもつながります。

![](https://storage.googleapis.com/zenn-user-upload/36f0deab48f9-20251223.jpg)
*人/AIが読みにくいコード*

![](https://storage.googleapis.com/zenn-user-upload/b5b5500cb778-20251223.jpg)
*人/AIが読みやすいコード*

> 「コードは他の人が最短時間で理解できるように書かなければいけない」
>  --*『The Art of Readable Code』（Dustin Boswell、Trevor Foucher）*

これからはAIのためのリーダブルコードでもあるべきだと思っています。


# "今はまだ"時短にはならない

## プロトタイピングはかなり楽に

PoCやプロトタイピングは、AIツールの導入で単純に工数削減することができるでしょう。

GitHubの調査では、[GitHub Copilotを使用した開発者はタスクを55%速く完了した](https://github.blog/jp/2022-09-15-research-quantifying-github-copilots-impact-on-developer-productivity-and-happiness/)という報告がありますし、Harness社の調査では、[GitHub Copilot導入後にサイクルタイムが平均3.5時間短縮（2.4%改善）し、PRの数が10.6%増加した](https://www.harness.io/blog/the-impact-of-github-copilot-on-developer-productivity-a-case-study)という報告も出ています。
（まあポジショントークの可能性もありますが…）

実際私も過去に技術検証ついでにアプリケーションを作った際も、それまでは知見のなかった技術スタックにも関わらず短時間での開発ができています。ゼロから自分で書いていたら数倍の時間がかかっていたと思います。

## チームプロジェクトにはまだ壁が

一方で、チームでのプロジェクト開発においてAI駆動開発を導入するにはまだまだ課題があると思っています。

私が直近参加した勉強でも、ジュニア／シニアに関わらず以下のような意見が出ていました。
- 設計やコードなどレビューの量が多い
- 長々と設計計画が出力されていて読むのはつらいが、なんとなくいけそうな気がする
- 生成を待つのでトライ＆エラーに時間がかかる
- ドキュメントの管理がしんどい
- プロンプトを育てるのが大変

先ほどはAIツールの肯定的な調査結果を引用しましたが、一方で短期的な効率化が難しいことを示す調査もあります。
[Uplevel Data Labsが2024年に約800人の開発者を対象に行った調査](https://devops.com/study-finds-no-devops-productivity-gains-from-generative-ai/)では、GitHub Copilot使用者は非使用時と比べてバグ率が41%増加した一方で、プルリクエスト数などに有意な改善が見られなかったという結果が出ています。


## 条件と期間が確保できるとき

まだ個人的な考えの域を出ませんが、例えば

- メンバーがレビューの勘所を持っている
- 手戻りを最小限にできる
- チームがドキュメントの管理を怠らない

などの条件がそろったとき、ようやくチーム開発においてAIツール導入による効率化が達成できる可能性がある、というのが今のレベルだと思います。
今後のツールの進歩、またはチーム開発手法の改善によっては劇的に変化する可能性もありますが、まずは今すぐの効率化は半ば難しいと考えてじっくり整備して導入していく必要があると思っています。


# いつでも捨てる覚悟を持つ

## コーディングエージェント年表
いきなりですが、コーディングエージェントのリリース年表を作ってみました。
有名どころのツールを恣意的に抜き出してますし、モデルとか多種多様なAIツールは省いていますが、それでもこの2年間、毎月のようにコーディングエージェントがリリースされています。
![](https://storage.googleapis.com/zenn-user-upload/6e1afaa634bd-20251223.jpg)


## ツールの数だけ増えるファイル群
そしてコーディングエージェントをはじめとして、多くのAIツールが開発者のローカルPCに専用の設定ファイルなどを必要とします。
![](https://storage.googleapis.com/zenn-user-upload/67a4e856b7f1-20251223.jpg)


## 流動的なツールたち
一方で、今日私たちが使っているツールが、明日も同じように使えるとは限りません。

例えば、今使っているモデルが明日には古いバージョンになっているかもしれません。
実際2025年11月には以下のモデルが立て続けにリリースされて、コーディング性能のトップ層が数日で入れ替わり続けるという事態にもなりました。
 - 11/18 Gemini 3
 - 11/19 GPT-5.1-Codex-Max
 - 11/24 Claude Opus 4.5

また例えば、今使っているツールが明日には料金や方針、体制が変わるかもしれません。
2025年7月には、AIコードエディタであるWindsurfのトップ層がGoogleに引き抜かれたというニュースもありました。

さらに例えば、今使っているファイルが明日には陳腐化するかもしれません。
2025年12月現在、コーディングエージェントの特定タスクに特化したカスタムコマンドとしてAgent Skillsが潮流となり、MCPやカスタムプロンプトなどの設定からの移行が始まっています。

という具合にツールの明日はわからない状況です。

少し話がそれますが、[Gartnerのハイプ・サイクル](https://www.gartner.co.jp/ja/research/methodologies/gartner-hype-cycle)というものがあります。
時間と期待度の2軸で、技術が開発されて普及していくまでの成熟度と採用度を表しているものです。

![](https://storage.googleapis.com/zenn-user-upload/fb774276e4c9-20251223.png)
*https://www.gartner.co.jp/ja/newsroom/press-releases/pr-20251001-infratech-hc*
まあ2025年のハイプサイクルはこんな感じ👆なので、正直信憑性は薄いと個人的には思っていますが、考え方を踏襲しつつもっとミクロな観点に立つと、「私が使っているこのモデル」「私が使っているあのツール」がいずれ普及の波に置いて行かれる可能性は十分にあります。

> 「幻滅の谷に落ちた技術の約60%は復活しない」
> --*The Economist*

なんていう話もあります。
幻滅期に入ったツールが復活する可能性を待つか、それとも次に有望なツールを導入するか、そういった選択がいま私たちが使っているツールに訪れる可能性は十分あると思います。
いずれにしてもいつでもツールに見切りをつけるなり、移行するなりの心構えを持っておく必要はあると思っています。


# おしまい

今回はAI駆動開発について個人的な考えを書いてみました。
あんまり主観的になるのもあれなのでちょいちょい数字を引用しつつ書いてみましたが、当の私自身は特に偉そうなことを言えるほどチームでのAI駆動開発ができているわけでもありません。
まだまだ個人で好きにツールを触って遊んでいる程度なので、今後真面目にチームでの活用を考えていきたいと思っています。
今回はその一歩目ということで自分の中の課題を整理する機会となりました。